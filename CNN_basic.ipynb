{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caa9437-b965-47bf-85c7-315a3984dd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3737566-cc40-4454-8fb2-d7b91e5b9b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Implement the following function, which pads all the images of a batch of examples X with zeros. Use np.pad. Note if you want to pad the array \"a\" of shape  (5,5,5,5,5)\n",
    "  with pad = 1 for the 2nd dimension, pad = 3 for the 4th dimension and pad = 0 for the rest, you would do:\n",
    "a = np.pad(a, ((0,0), (1,1), (0,0), (3,3), (0,0)), mode='constant', constant_values = (0,0))\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#Zero_Pad\n",
    "def zero_pad(X, pad):\n",
    "    \"\"\"\n",
    "    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image.\n",
    "\n",
    "    Argument:\n",
    "    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images\n",
    "    pad -- integer, amount of padding around each image on vertical and horizontal dimensions\n",
    "\n",
    "    Returns:\n",
    "    X_pad -- padded image of shape (m, n_H + 2 * pad, n_W + 2 * pad, n_C). Typical example: m = batch size, n_C = 3 (RGB)\n",
    "    \"\"\"\n",
    "    X_pad = np.pad(\n",
    "        X,\n",
    "        pad_width=((0, 0),          # no padding on examples dimension (m)\n",
    "                   (pad, pad),      # pad top and bottom (height)\n",
    "                   (pad, pad),      # pad left and right (width)\n",
    "                   (0, 0)),         # no padding on channels dimension (n_C)\n",
    "        mode='constant',            # pad with constant value (default = 0)\n",
    "        constant_values=0\n",
    "    )\n",
    "\n",
    "    return X_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdba33c9-6066-4be9-8afd-df95bd4626fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(4, 3, 3, 2)\n",
    "x_pad = zero_pad(x, 3)\n",
    "print (\"x.shape =\\n\", x.shape)\n",
    "print (\"x_pad.shape =\\n\", x_pad.shape)\n",
    "print (\"x[1,1] =\\n\", x[1, 1])\n",
    "print (\"x_pad[1,1] =\\n\", x_pad[1, 1])\n",
    "\n",
    "fig, axarr = plt.subplots(1, 2)\n",
    "axarr[0].set_title('x')\n",
    "axarr[0].imshow(x[0, :, :, 0])\n",
    "axarr[1].set_title('x_pad')\n",
    "axarr[1].imshow(x_pad[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3190a86-7c41-4763-a4d1-5332ffad16e1",
   "metadata": {},
   "source": [
    "## Single Step of Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8764d0-e0b0-4201-a8d1-ce392e8ea453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_single_step(a_slice_prev, W, b):\n",
    "    \"\"\"\n",
    "    Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation\n",
    "    of the previous layer.\n",
    "\n",
    "    Arguments:\n",
    "    a_slice_prev -- slice of input data of shape (f, f, n_C_prev)\n",
    "    W -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev)\n",
    "    b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)\n",
    "\n",
    "    Returns:\n",
    "    Z -- a scalar value, the result of convolving the sliding window (W, b) on a slice x of the input data\n",
    "    \"\"\"\n",
    "    # Element-wise product between a_slice_prev and W. Do not add the bias yet.\n",
    "    s = a_slice_prev * W\n",
    "    \n",
    "    # Sum over all entries of the volume s\n",
    "    Z = np.sum(s)\n",
    "    \n",
    "    # Add bias to Z. Cast b to a float() so that Z results in a scalar value.\n",
    "    Z = Z + float(b)\n",
    "\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4466691e-ef26-4ca9-978f-3aab441acd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "a_slice_prev = np.random.randn(4, 4, 3)\n",
    "W = np.random.randn(4, 4, 3)\n",
    "b = np.random.randn(1, 1, 1)\n",
    "\n",
    "Z = conv_single_step(a_slice_prev, W, b)\n",
    "print(\"Z =\", Z)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc22bc5-f57c-4637-bc61-ba0af004492f",
   "metadata": {},
   "source": [
    "In the forward pass, you will take many filters and convolve them on the input. Each 'convolution' gives you a 2D matrix output. You will then stack these outputs to get a 3D volume:\n",
    "<center>\n",
    "<video width=\"620\" height=\"440\" src=\"convolution_illus.mp4\" type=\"video/mp4\" controls>\n",
    "</video>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8ca59f-8a91-49ab-9259-febae17f7719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward(A_prev, W, b, hparameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for a convolution function\n",
    "\n",
    "    Arguments:\n",
    "    A_prev -- output activations of the previous layer,\n",
    "        numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)\n",
    "    b -- Biases, numpy array of shape (1, 1, 1, n_C)\n",
    "    hparameters -- python dictionary containing \"stride\" and \"pad\"\n",
    "\n",
    "    Returns:\n",
    "    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache -- cache of values needed for the conv_backward() function\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve dimensions from A_prev's shape (\u22481 line)\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve dimensions from W's shape (\u22481 line)\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    \n",
    "    # Retrieve information from \"hparameters\" (\u22482 lines)\n",
    "    stride = hparameters[\"stride\"]\n",
    "    pad = hparameters[\"pad\"]\n",
    "    \n",
    "    # Compute the dimensions of the CONV output volume using the formula given above. Hint: use int() to floor. (\u22482 lines)\n",
    "    n_H = int((n_H_prev + 2 * pad - f) / stride + 1)\n",
    "    n_W = int((n_W_prev + 2 * pad - f) / stride + 1)\n",
    "    \n",
    "    # Initialize the output volume Z with zeros.\n",
    "    Z = np.zeros((m, n_H, n_W, n_C))\n",
    "    \n",
    "    # Create A_prev_pad by padding A_prev\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    \n",
    "    # loop over the batch of training examples\n",
    "    for i in range(m):\n",
    "        # Select ith training example's padded activation\n",
    "        a_prev_pad = A_prev_pad[i]          # shape: (n_H_prev + 2*pad, n_W_prev + 2*pad, n_C_prev)\n",
    "        \n",
    "        # loop over vertical axis of the output volume\n",
    "        for h in range(n_H):\n",
    "            # Find the vertical start and end of the current \"slice\" (\u22482 lines)\n",
    "            vert_start = h * stride\n",
    "            vert_end   = vert_start + f\n",
    "            \n",
    "            # loop over horizontal axis of the output volume\n",
    "            for w in range(n_W):\n",
    "                # Find the horizontal start and end of the current \"slice\" (\u22482 lines)\n",
    "                horiz_start = w * stride\n",
    "                horiz_end   = horiz_start + f\n",
    "                \n",
    "                # loop over channels (= #filters) of the output volume\n",
    "                for c in range(n_C):\n",
    "                    # Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). (\u22481 line)\n",
    "                    a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "                    \n",
    "                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (\u22483 line)\n",
    "                    weights = W[:, :, :, c]          # shape (f, f, n_C_prev)\n",
    "                    biases  = b[:, :, :, c]          # shape (1,1,1) or just scalar after squeezing\n",
    "                    Z[i, h, w, c] = conv_single_step(a_slice_prev, weights, biases)\n",
    "\n",
    "\n",
    "    # Save information in \"cache\" for the backprop\n",
    "    cache = (A_prev, W, b, hparameters)\n",
    "\n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deefdcd-3e0f-4bf5-a9a9-9ac4ef855dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(2, 5, 7, 4)\n",
    "W = np.random.randn(3, 3, 4, 8)\n",
    "b = np.random.randn(1, 1, 1, 8)\n",
    "hparameters = {\"pad\" : 1,\n",
    "               \"stride\": 2}\n",
    "\n",
    "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
    "z_mean = np.mean(Z)\n",
    "z_0_2_1 = Z[0, 2, 1]\n",
    "cache_0_1_2_3 = cache_conv[0][1][2][3]\n",
    "print(\"Z's mean =\\n\", z_mean)\n",
    "print(\"Z[0,2,1] =\\n\", z_0_2_1)\n",
    "print(\"cache_conv[0][1][2][3] =\\n\", cache_0_1_2_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9edeae-6349-422c-b72f-feb851b8295e",
   "metadata": {},
   "source": [
    "## Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4449bba7-8ff4-40d3-b410-987c799e49dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
    "    \"\"\"\n",
    "    Implements the forward pass of the pooling layer\n",
    "\n",
    "    Arguments:\n",
    "    A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    hparameters -- python dictionary containing \"f\" and \"stride\"\n",
    "    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n",
    "\n",
    "    Returns:\n",
    "    A -- output of the pool layer, a numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache -- cache used in the backward pass of the pooling layer, contains the input and hparameters\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve dimensions from the input shape\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "\n",
    "    # Retrieve hyperparameters from \"hparameters\"\n",
    "    f = hparameters[\"f\"]\n",
    "    stride = hparameters[\"stride\"]\n",
    "\n",
    "    # Define the dimensions of the output\n",
    "    n_H = int(1 + (n_H_prev - f) / stride)\n",
    "    n_W = int(1 + (n_W_prev - f) / stride)\n",
    "    n_C = n_C_prev\n",
    "\n",
    "    # Initialize output matrix A\n",
    "    A = np.zeros((m, n_H, n_W, n_C))\n",
    "\n",
    "    for i in range(m):\n",
    "        # loop on the vertical axis of the output volume\n",
    "        for h in range(n_H):\n",
    "            # loop on the horizontal axis of the output volume\n",
    "            for w in range(n_W):\n",
    "                # loop over the channels of the output volume\n",
    "                for c in range(n_C):\n",
    "                    # Find the corners of the current \"slice\"\n",
    "                    vert_start  = h * stride\n",
    "                    vert_end    = vert_start + f\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end   = horiz_start + f\n",
    "                    \n",
    "                    # Use the corners to define the current slice on the ith training example of A_prev, channel c.\n",
    "                    a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                    \n",
    "                    # Compute the pooling operation on the slice.\n",
    "                    # Use an if statement to differentiate the modes.\n",
    "                    # Use np.max / np.mean.\n",
    "                    if mode == \"max\":\n",
    "                        A[i, h, w, c] = np.max(a_prev_slice)\n",
    "                    elif mode == \"average\":\n",
    "                        A[i, h, w, c] = np.mean(a_prev_slice)\n",
    "\n",
    "    # Store the input and hparameters in \"cache\" for pool_backward()\n",
    "    cache = (A_prev, hparameters)\n",
    "\n",
    "    # Making sure your output shape is correct\n",
    "    #assert(A.shape == (m, n_H, n_W, n_C))\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a55a07-ad55-4aaf-a03a-088e8b81b66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case 1: stride of 1\n",
    "print(\"CASE 1:\\n\")\n",
    "np.random.seed(1)\n",
    "A_prev_case_1 = np.random.randn(2, 5, 5, 3)\n",
    "hparameters_case_1 = {\"stride\" : 1, \"f\": 3}\n",
    "\n",
    "A, cache = pool_forward(A_prev_case_1, hparameters_case_1, mode = \"max\")\n",
    "print(\"mode = max\")\n",
    "print(\"A.shape = \" + str(A.shape))\n",
    "print(\"A[1, 1] =\\n\", A[1, 1])\n",
    "A, cache = pool_forward(A_prev_case_1, hparameters_case_1, mode = \"average\")\n",
    "print(\"mode = average\")\n",
    "print(\"A.shape = \" + str(A.shape))\n",
    "print(\"A[1, 1] =\\n\", A[1, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c305897-5f96-4ea0-978e-3d7c9fe65403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case 2: stride of 2\n",
    "print(\"\\n\\033[0mCASE 2:\\n\")\n",
    "np.random.seed(1)\n",
    "A_prev_case_2 = np.random.randn(2, 5, 5, 3)\n",
    "hparameters_case_2 = {\"stride\" : 2, \"f\": 3}\n",
    "\n",
    "A, cache = pool_forward(A_prev_case_2, hparameters_case_2, mode = \"max\")\n",
    "print(\"mode = max\")\n",
    "print(\"A.shape = \" + str(A.shape))\n",
    "print(\"A[0] =\\n\", A[0])\n",
    "print()\n",
    "\n",
    "A, cache = pool_forward(A_prev_case_2, hparameters_case_2, mode = \"average\")\n",
    "print(\"mode = average\")\n",
    "print(\"A.shape = \" + str(A.shape))\n",
    "print(\"A[1] =\\n\", A[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34398071-3a6c-4bf5-a478-99a60b0e8210",
   "metadata": {},
   "source": [
    "## Backpropagation in CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23723fe8-55ef-4171-bbc7-95008470e52d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcfd4847-2b86-4594-a8f3-c3793eb20e74",
   "metadata": {},
   "source": [
    "Residual Networks, introduced by He et al., allow you to train much deeper networks than were previously feasible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f35b91-19c4-4a4a-8a9f-9bff718fc611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ffa15d-5950-4fc3-b64b-68d36d57e0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.framework.ops import EagerTensor\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "import os\n",
    "import h5py\n",
    "import math\n",
    "from resnets_utils import *\n",
    "from keras.layers import Layer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a31d84-17fc-483f-a62e-16b310f3092c",
   "metadata": {},
   "source": [
    "ResNet blocks with the shortcut makes it very easy for one of the blocks to learn an identity function. This means that you can stack on additional ResNet blocks with little risk of harming training set performance (slow speed due to vanishing gradient). There is also some evidence that the ease of learning an identity function accounts for ResNets' remarkable performance even more than skip connections help with vanishing gradients.\n",
    "\n",
    "Two main types of blocks are used in a ResNet, depending mainly on whether the input/output dimensions are the same or different. You are going to implement both of them: the \"identity block\" and the \"convolutional block.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2758d6-b45d-4693-8e7a-9551d5b78771",
   "metadata": {},
   "source": [
    "## The Identity Block\n",
    "\n",
    "<img src=\"images/idblock2_kiank.png\" style=\"width:650px;height:150px;\">\n",
    "\n",
    "Can also skip over multiple layers\n",
    "\n",
    "<img src=\"images/idblock3_kiank.png\" style=\"width:650px;height:150px;\">\n",
    "    <caption><center> <u> <font color='purple'> <b>Figure 2</b> </u><font color='purple'>  : <b>Identity block.</b> Skip connection \"skips over\" 3 layers.</center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9658d18b-1361-4003-b661-c29d7b33e29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters,training=False, initializer=random_uniform):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block as defined in Figure 2 above\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    initializer -- to set up the initial weights of a layer. Equals to random uniform initializer\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (m, n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "   # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "   \n",
    "    # Save the input value (shortcut)\n",
    "    X_shortcut = X\n",
    "   \n",
    "    # First component of main path\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters=F1, kernel_size=1, strides=(1,1), padding='valid',\n",
    "        kernel_initializer=initializer(seed=0)\n",
    "    )(X)\n",
    "    X = tf.keras.layers.BatchNormalization(axis=3)(X, training=training)\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "   \n",
    "    # Second component of main path\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters=F2, kernel_size=f, strides=(1,1), padding='same',\n",
    "        kernel_initializer=initializer(seed=0)\n",
    "    )(X)\n",
    "    X = tf.keras.layers.BatchNormalization(axis=3)(X, training=training)\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "  \n",
    "    # Third component of main path\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters=F3, kernel_size=1, strides=(1,1), padding='valid',\n",
    "        kernel_initializer=initializer(seed=0)\n",
    "    )(X)\n",
    "    X = tf.keras.layers.BatchNormalization(axis=3)(X, training=training)\n",
    "  \n",
    "    # Final step: Add shortcut + main path, then ReLU\n",
    "    X = tf.keras.layers.Add()([X, X_shortcut])\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b24bb14-9c8c-458a-998c-732a5edc87cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the identity block\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(2)\n",
    "\n",
    "X1 = np.ones((1, 4, 4, 3)) * -1\n",
    "X2 = np.ones((1, 4, 4, 3)) * 1\n",
    "X3 = np.ones((1, 4, 4, 3)) * 3\n",
    "X = np.concatenate((X1, X2, X3), axis=0).astype(np.float32)\n",
    "\n",
    "print('\\033[1mWith training=False\\033[0m\\n')\n",
    "A3 = identity_block(X, f=2, filters=[4, 4, 3],\n",
    "                    training=False,                                    # \u2190 important\n",
    "                    initializer=lambda seed=0: tf.keras.initializers.Constant(value=1))\n",
    "\n",
    "A3np = A3.numpy()\n",
    "print(np.around(A3.numpy()[:, (0,-1), :, :].mean(axis=3), 5))\n",
    "resume = A3np[:, (0,-1), :, :].mean(axis=3)\n",
    "print(resume[1, 1, 0])\n",
    "\n",
    "print('\\n\\033[1mWith training=True\\033[0m\\n')\n",
    "A4 = identity_block(X, f=2, filters=[3, 3, 3],\n",
    "                    training=True,                                     # \u2190 important\n",
    "                    initializer=lambda seed=0: tf.keras.initializers.Constant(value=1))\n",
    "\n",
    "print(np.around(A4.numpy()[:, (0,-1), :, :].mean(axis=3), 5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5a79c8-0986-49cd-bb0b-92dde63c2980",
   "metadata": {},
   "source": [
    "## The Convolutional Block\n",
    "\n",
    "\n",
    "You can use this type of block when the input and output dimensions don't match up. The difference with the identity block is that there is a CONV2D layer in the shortcut path (does not use any non-linear activation function): The CONV2D layer in the shortcut path is simply used to resize the input  \ud835\udc65 to a different dimension, so that the dimensions match up in the final addition needed to add the shortcut value back to the main path.\n",
    "\n",
    "<img src=\"images/convblock_kiank.png\" style=\"width:650px;height:150px;\">\n",
    "<caption><center> <u> <font color='purple'> <b>Figure 3</b> </u><font color='purple'>  : <b>Convolutional block</b> </center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ab2adb-eb42-4b45-bbf7-4aa3610ae34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, s = 2, training=False, \n",
    "                        initializer=tf.keras.initializers.glorot_uniform):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block as defined in Figure 3\n",
    "    \"\"\"\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = 1, strides = (s, s), padding = 'valid',\n",
    "               kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)   # \u2190 critical line\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters = F2, kernel_size = f, strides = (1, 1), padding = 'same',\n",
    "               kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)   # \u2190 critical\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters = F3, kernel_size = 1, strides = (1, 1), padding = 'valid',\n",
    "               kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)   # \u2190 critical\n",
    "    # NO ReLU here\n",
    "\n",
    "    ##### SHORTCUT PATH ##### \n",
    "    X_shortcut = Conv2D(filters = F3, kernel_size = 1, strides = (s, s), padding = 'valid',\n",
    "                        kernel_initializer = initializer(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3)(X_shortcut, training=training)   # \u2190 critical\n",
    "\n",
    "    # Final step: Add shortcut to main path, then ReLU\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a0eb30-a410-4bf1-9458-d2db80f54204",
   "metadata": {},
   "source": [
    "## Building a 50 Layer ResNet Model\n",
    "\n",
    "The following figure describes in detail the architecture of this neural network. \"ID BLOCK\" in the diagram stands for \"Identity block,\" and \"ID BLOCK x3\" means you should stack 3 identity blocks together.\n",
    "\n",
    "<img src=\"images/resnet_kiank.png\" style=\"width:850px;height:150px;\">\n",
    "<caption><center> <u> <font color='purple'> <b>Figure 4</b> </u><font color='purple'>  : <b>ResNet-50 model</b> </center></caption>\n",
    "\n",
    "The details of this ResNet-50 model are:\n",
    "- Zero-padding pads the input with a pad of (3,3)\n",
    "- Stage 1:\n",
    "    - The 2D Convolution has 64 filters of shape (7,7) and uses a stride of (2,2). \n",
    "    - BatchNorm is applied to the 'channels' axis of the input.\n",
    "    - MaxPooling uses a (3,3) window and a (2,2) stride.\n",
    "- Stage 2:\n",
    "    - The convolutional block uses three sets of filters of size [64,64,256], \"f\" is 3, and \"s\" is 1.\n",
    "    - The 2 identity blocks use three sets of filters of size [64,64,256], and \"f\" is 3.\n",
    "- Stage 3:\n",
    "    - The convolutional block uses three sets of filters of size [128,128,512], \"f\" is 3 and \"s\" is 2.\n",
    "    - The 3 identity blocks use three sets of filters of size [128,128,512] and \"f\" is 3.\n",
    "- Stage 4:\n",
    "    - The convolutional block uses three sets of filters of size [256, 256, 1024], \"f\" is 3 and \"s\" is 2.\n",
    "    - The 5 identity blocks use three sets of filters of size [256, 256, 1024] and \"f\" is 3.\n",
    "- Stage 5:\n",
    "    - The convolutional block uses three sets of filters of size [512, 512, 2048], \"f\" is 3 and \"s\" is 2.\n",
    "    - The 2 identity blocks use three sets of filters of size [512, 512, 2048] and \"f\" is 3.\n",
    "- The 2D Average Pooling uses a window (pool_size) of shape (2,2).\n",
    "- The 'flatten' layer doesn't have any hyperparameters.\n",
    "- The Fully Connected (Dense) layer reduces its input to the number of classes using a softmax activation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec730d4-517b-423d-9fa2-3ca4a19a05c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape = (64, 64, 3), classes = 6, training=False):\n",
    "    \"\"\"\n",
    "    Stage-wise implementation of the architecture of the popular ResNet50:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> FLATTEN -> DENSE\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "   \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "   \n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "   \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), \n",
    "               kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2 \u2500\u2500 convolutional block uses glorot, identity blocks use random_uniform\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], s=1, \n",
    "                            training=training,\n",
    "                            initializer=glorot_uniform)\n",
    "\n",
    "    X = identity_block(X, 3, [64, 64, 256], training=training,\n",
    "                       initializer=random_uniform)\n",
    "    X = identity_block(X, 3, [64, 64, 256], training=training,\n",
    "                       initializer=random_uniform)\n",
    "\n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, f=3, filters=[128, 128, 512], s=2, \n",
    "                            training=training,\n",
    "                            initializer=glorot_uniform)\n",
    "\n",
    "    X = identity_block(X, 3, [128, 128, 512], training=training,\n",
    "                       initializer=random_uniform)\n",
    "    X = identity_block(X, 3, [128, 128, 512], training=training,\n",
    "                       initializer=random_uniform)\n",
    "    X = identity_block(X, 3, [128, 128, 512], training=training,\n",
    "                       initializer=random_uniform)\n",
    "\n",
    "    # Stage 4\n",
    "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], s=2, \n",
    "                            training=training,\n",
    "                            initializer=glorot_uniform)\n",
    "\n",
    "    X = identity_block(X, 3, [256, 256, 1024], training=training,\n",
    "                       initializer=random_uniform)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], training=training,\n",
    "                       initializer=random_uniform)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], training=training,\n",
    "                       initializer=random_uniform)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], training=training,\n",
    "                       initializer=random_uniform)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], training=training,\n",
    "                       initializer=random_uniform)\n",
    "\n",
    "    # Stage 5\n",
    "    X = convolutional_block(X, f=3, filters=[512, 512, 2048], s=2, \n",
    "                            training=training,\n",
    "                            initializer=glorot_uniform)\n",
    "\n",
    "    X = identity_block(X, 3, [512, 512, 2048], training=training,\n",
    "                       initializer=random_uniform)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], training=training,\n",
    "                       initializer=random_uniform)\n",
    "\n",
    "    # AVGPOOL\n",
    "    X = AveragePooling2D(pool_size=(2, 2))(X)\n",
    "   \n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', \n",
    "              kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "   \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0270f054-0702-4a16-aaa0-acd79874ab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.backend.set_learning_phase(True)\n",
    "\n",
    "model = ResNet50(input_shape = (64, 64, 3), classes = 6)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655c055b-d45d-4bf9-918f-900265f41a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "tf.random.set_seed(2)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00015)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e53fdf4-4202-4635-ac91-b44f90b3e168",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The model is now ready to be trained. The only thing you need now is a dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e812c45f-e7ad-43fe-97fa-96c62222c448",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_orig / 255.\n",
    "X_test = X_test_orig / 255.\n",
    "\n",
    "# Convert training and test labels to one hot matrices\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc9488e-67bc-4f17-be07-f06b2c8aee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs = 10, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1059ca4b-bb0b-4911-9bb4-a7961c9b1067",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d9c363-0ae9-49e8-ac42-0ac1bd1b4f25",
   "metadata": {},
   "source": [
    "Test accuracy may seem low. But, It tends to get much better performance when trained for ~20 epochs, but this does take more than an hour when training on a CPU.\n",
    "\n",
    "\n",
    "**What you should remember**:\n",
    "\n",
    "- Very deep \"plain\" networks don't work in practice because vanishing gradients make them hard to train.  \n",
    "- Skip connections help address the Vanishing Gradient problem. They also make it easy for a ResNet block to learn an identity function. \n",
    "- There are two main types of blocks: The **identity block** and the **convolutional block**. \n",
    "- Very deep Residual Networks are built by stacking these blocks together.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddd3e01-47f9-4aea-8e35-d3668f0fc564",
   "metadata": {},
   "source": [
    "## Running a Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e274bf-a59d-4b7c-ab22-4915fbe26882",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model = load_model('./models/resnet50.h5')  #from tensorflow.keras.models import Model, load_model\n",
    "preds = pre_trained_model.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e05658b-837c-4916-bd9d-b0d9c6bd4528",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d701095-6c5c-4914-9f74-b836423c7fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to test the model with your own image\n",
    "\n",
    "# Replace this with your image's filename\n",
    "img_path = 'images/sign2.jpg'\n",
    "\n",
    "img = image.load_img(img_path, target_size=(64, 64))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = x/255.0\n",
    "x2 = x \n",
    "print('Input image shape:', x.shape)\n",
    "imshow(img)\n",
    "prediction = pre_trained_model.predict(x2)\n",
    "print(\"Class prediction vector [p(0), p(1), p(2), p(3), p(4), p(5)] = \", prediction)\n",
    "print(\"Class:\", np.argmax(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e3f752-33f7-4c2c-92d2-b502c5ee3a65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
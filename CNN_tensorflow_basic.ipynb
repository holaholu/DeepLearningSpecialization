{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31c2162-81c0-44df-9896-bb0e79742c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n",
    "import math\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imread\n",
    "import scipy\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import tensorflow.keras.layers as tfl\n",
    "from tensorflow.python.framework import ops\n",
    "from termcolor import colored\n",
    "\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout \n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import ZeroPadding2D\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5622fe7a-85d9-450c-9d22-3c8a4f0cd0fc",
   "metadata": {},
   "source": [
    "## Load the Data and Split the Data into Train/Test Sets\n",
    "We will be using the Happy House dataset. Our task will be to build a ConvNet that determines whether the people in the images are smiling or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de98287-426b-4627-ae42-c9d028b59645",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_happy_dataset():\n",
    "    train_dataset = h5py.File('datasets/train_happy.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('datasets/test_happy.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
    "    \n",
    "\n",
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_happy_dataset()\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "\n",
    "# Reshape\n",
    "Y_train = Y_train_orig.T\n",
    "Y_test = Y_test_orig.T\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6845551c-9025-4bd9-90f7-c4894d3db751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets view an image\n",
    "index = 124\n",
    "plt.imshow(X_train_orig[index]) #display sample training image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a66f98-6c49-4056-b34c-e808ab18e815",
   "metadata": {},
   "source": [
    "## Create the Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bb3b70-f2d5-460a-a798-74cca6dcc941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def happyModel():\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the binary classification model:\n",
    "    ZEROPAD2D -> CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> FLATTEN -> DENSE\n",
    "\n",
    "    \n",
    "\n",
    "    Returns:\n",
    "    model -- TF Keras model (object containing the information for the entire training process)\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "\n",
    "        # ZeroPadding2D with padding 3, input shape of 64 x 64 x 3\n",
    "        tfl.ZeroPadding2D(padding=3, input_shape=(64, 64, 3)),\n",
    "        \n",
    "        # Conv2D with 32 7x7 filters and stride of 1\n",
    "        tfl.Conv2D(filters=32, kernel_size=7, strides=1),\n",
    "        \n",
    "        # BatchNormalization for axis 3\n",
    "        tfl.BatchNormalization(axis=3),\n",
    "        \n",
    "        # ReLU\n",
    "        tfl.ReLU(),\n",
    "        \n",
    "        # Max Pooling 2D with default parameters (pool_size=(2,2), strides=(2,2))\n",
    "        tfl.MaxPooling2D(),\n",
    "        \n",
    "        # Flatten layer\n",
    "        tfl.Flatten(),\n",
    "        \n",
    "        # Dense layer with 1 unit for output & 'sigmoid' activation\n",
    "        tfl.Dense(units=1, activation='sigmoid')\n",
    "\n",
    "        ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db79063c-1929-46c9-a0d7-19d7aec64c81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def summary(model):\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    result = []\n",
    "    for layer in model.layers:\n",
    "        descriptors = [layer.__class__.__name__, layer.output.shape, layer.count_params()]\n",
    "        if (type(layer) == Conv2D):\n",
    "            descriptors.append(layer.padding)\n",
    "            descriptors.append(layer.activation.__name__)\n",
    "            descriptors.append(layer.kernel_initializer.__class__.__name__)\n",
    "        if (type(layer) == MaxPooling2D):\n",
    "            descriptors.append(layer.pool_size)\n",
    "            descriptors.append(layer.strides)\n",
    "            descriptors.append(layer.padding)\n",
    "        if (type(layer) == Dropout):\n",
    "            descriptors.append(layer.rate)\n",
    "        if (type(layer) == ZeroPadding2D):\n",
    "            descriptors.append(layer.padding)\n",
    "        if (type(layer) == Dense):\n",
    "            descriptors.append(layer.activation.__name__)\n",
    "        result.append(descriptors)\n",
    "    return result\n",
    "    \n",
    "happy_model = happyModel()\n",
    "# Print a summary for each layer\n",
    "\n",
    "for layer in summary(happy_model):\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d0c7d8-2e77-4103-86b6-4f1414106f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model for training with optimizer and loss of choice\n",
    "happy_model.compile(optimizer='adam',\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd3f120-a2f8-4a34-bfda-803559a1c03b",
   "metadata": {},
   "source": [
    "It's time to check your model's parameters with the .summary() method. This will display the types of layers you have, the shape of the outputs, and how many parameters are in each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c96d63-ada9-4496-8329-f1ac06ede4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f504bef2-6038-4e4e-b3cd-7953ef455526",
   "metadata": {},
   "source": [
    "Conv2d_7 parameter numbers = (filter/kernel size * number of channels of input * total number of filters) + bias for each filter = (7*7 * 3 * 32)  + 32 = 4736"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49b706e-1b36-4cb1-b7a6-c42c2ec27113",
   "metadata": {},
   "source": [
    "## Train and Evaluate the Model\n",
    "\n",
    " You do have the option to specify epoch number or minibatch size if you like (for example, in the case of an un-batched dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb1380d-4d0f-46a5-910b-6e45a9da6f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_model.fit(X_train, Y_train, epochs=10, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee62bd18-211b-4aa4-a87b-a26ad503e830",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use .evaluate() to evaluate against your test set. This function will print the value of the loss function and the performance metrics specified during the compilation of the model. In this case, the binary_crossentropy and the accuracy respectively.\n",
    "\n",
    "happy_model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed68c0fb-d5dd-46eb-94b4-e39c04c84c4e",
   "metadata": {},
   "source": [
    "But what if you need to build a model with shared layers, branches, or multiple inputs and outputs? This is where Sequential, with its beautifully simple yet limited functionality, won't be able to help you.Functional API is needed.It is slightly more complex but highly flexible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cda1ac2-7134-4c25-b2ce-9c46a43cf88f",
   "metadata": {},
   "source": [
    "## The Functional API\n",
    "\n",
    "The Functional API can handle models with non-linear topology, shared layers, as well as layers with multiple inputs or outputs. Imagine that, where the Sequential API requires the model to move in a linear fashion through its layers, the Functional API allows much more flexibility. Where Sequential is a straight line, a Functional model is a graph, where the nodes of the layers can connect in many more ways than one.\n",
    "\n",
    "In the Functional API, you create a graph of layers. This is what allows such great flexibility.\n",
    "\n",
    "We will use Keras' flexible Functional API to build a ConvNet that can differentiate between 6 sign language digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b275459c-cd39-4d5a-91d3-a1b15129ba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Dataset\n",
    "def load_signs_dataset():\n",
    "    train_dataset = h5py.File('datasets/train_signs.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('datasets/test_signs.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
    "\n",
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_signs_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcf9c94-75b6-4d3f-8625-cf3cdf6098d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of an image from the dataset\n",
    "index = 9\n",
    "plt.imshow(X_train_orig[index])\n",
    "print (\"y = \" + str(np.squeeze(Y_train_orig[:, index])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c0ad85-db28-4cef-9532-433864c12b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y\n",
    "\n",
    "#Preprocess the data\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.        \n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
    "\n",
    "#Examine Shape of data\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92b8893-d0a0-4e7b-8a83-b614939043a3",
   "metadata": {},
   "source": [
    "NOTES\n",
    "\n",
    "tf.keras.layers.Flatten(): given a tensor \"P\", this function takes each training (or test) example in the batch and flattens it into a 1D vector.\n",
    "tf.keras.layers.Dense(units= ... , activation='softmax')(F): given the flattened input F, it returns the output computed using a fully connected layer. \n",
    "\n",
    "The words \"kernel\" and \"filter\" are used to refer to the same thing. The word \"filter\" accounts for the amount of \"kernels\" that will be used in a single convolution layer. \"Pool\" is the name of the operation that takes the max or average value of the kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc62ed2-f7cc-4570-8484-b73553b9960b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_model(input_shape):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> DENSE\n",
    "\n",
    "    Arguments:\n",
    "    input_img -- input dataset, of shape (input_shape)\n",
    "\n",
    "    Returns:\n",
    "    model -- TF Keras model (object containing the information for the entire training process)\n",
    "    \"\"\"\n",
    "\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "\n",
    "    # CONV2D: 8 filters of 4x4, stride of 1, padding 'SAME'-in conv2D, padding is chosing such that the output shape remains the same\n",
    "    Z1 = tf.keras.layers.Conv2D(\n",
    "        filters=8,\n",
    "        kernel_size=(4, 4),\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        name='conv1'\n",
    "    )(input_img)\n",
    "    \n",
    "    # RELU\n",
    "    A1 = tf.keras.layers.ReLU()(Z1)\n",
    "    \n",
    "    # MAXPOOL: window 8x8, stride 8, padding 'SAME'\n",
    "    P1 = tf.keras.layers.MaxPooling2D(\n",
    "        pool_size=(8, 8),\n",
    "        strides=8,\n",
    "        padding='same',\n",
    "        name='pool1'\n",
    "    )(A1)\n",
    "    \n",
    "    # CONV2D: 16 filters of 2x2, stride 1, padding 'SAME'\n",
    "    Z2 = tf.keras.layers.Conv2D(\n",
    "        filters=16,\n",
    "        kernel_size=(2, 2),\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        name='conv2'\n",
    "    )(P1)\n",
    "    \n",
    "    # RELU\n",
    "    A2 = tf.keras.layers.ReLU()(Z2)\n",
    "    \n",
    "    # MAXPOOL: window 4x4, stride 4, padding 'SAME'\n",
    "    P2 = tf.keras.layers.MaxPooling2D(\n",
    "        pool_size=(4, 4),\n",
    "        strides=4,\n",
    "        padding='same',\n",
    "        name='pool2'\n",
    "    )(A2)\n",
    "    \n",
    "    # FLATTEN\n",
    "    F = tf.keras.layers.Flatten()(P2)\n",
    "    \n",
    "    # Dense layer: 6 neurons, softmax activation\n",
    "    # (for 6-class classification)\n",
    "    outputs = tf.keras.layers.Dense(\n",
    "        units=6,\n",
    "        activation='softmax',\n",
    "        name='dense_output'\n",
    "    )(F)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input_img, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27577f6d-728f-4517-9f14-cc5d0e104a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model = convolutional_model((64, 64, 3))\n",
    "conv_model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "conv_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e0196c-4f80-495e-b50c-07506acbfc36",
   "metadata": {},
   "source": [
    "Conv1 parameter numbers = (filter/kernel size * number of channels of input * total number of filters) + bias for each filter = (4*4 * 3 * 8)  + 8 = 392\n",
    "\n",
    "Conv2 parameter numbers = (filter/kernel size * number of channels of input * total number of filters) + bias for each filter = (2*2 * 8 * 1)  + 16 = 528"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc1f2e4-dbbd-4097-b6e2-25eaaf1c0bef",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84637261-5ebc-4286-8e6a-d442ce61811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).batch(64)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test)).batch(64)\n",
    "history = conv_model.fit(train_dataset, epochs=100, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d665fa-6dea-4529-ad65-6e61ef3851a5",
   "metadata": {},
   "source": [
    "## History Object\n",
    "\n",
    "The history object is an output of the .fit() operation, and provides a record of all the loss and metric values in memory. It's stored as a dictionary that you can retrieve at history.history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26236a6-ea1f-4470-a560-15e1e043fa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a21b17-5d4c-4b33-b41a-94618b372529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The history.history[\"loss\"] entry is a dictionary with as many values as epochs that the\n",
    "# model was trained on.\n",
    "df_loss_acc = pd.DataFrame(history.history)\n",
    "df_loss= df_loss_acc[['loss','val_loss']]\n",
    "df_loss.rename(columns={'loss':'train','val_loss':'validation'},inplace=True)\n",
    "df_acc= df_loss_acc[['accuracy','val_accuracy']]\n",
    "df_acc.rename(columns={'accuracy':'train','val_accuracy':'validation'},inplace=True)\n",
    "df_loss.plot(title='Model loss',figsize=(12,8)).set(xlabel='Epoch',ylabel='Loss')\n",
    "df_acc.plot(title='Model Accuracy',figsize=(12,8)).set(xlabel='Epoch',ylabel='Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd4e12f-3016-4e1a-90fb-0614a22a23ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}